{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772fa2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import pytest\n",
    "import time\n",
    "from core.common.performance_monitor import MetricSnapshot, PerformanceHistory, ResourceMonitor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3994b20",
   "metadata": {},
   "source": [
    "## Test MetricSnapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2310636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_metric_snapshot_creation():\n",
    "    \"\"\"Test MetricSnapshot creation\"\"\"\n",
    "    snapshot = MetricSnapshot(\n",
    "        timestamp=time.time(),\n",
    "        cpu_percent=50.0,\n",
    "        memory_percent=60.0,\n",
    "        disk_percent=70.0,\n",
    "        network_sent=1000,\n",
    "        network_recv=2000\n",
    "    )\n",
    "    \n",
    "    assert snapshot.cpu_percent == 50.0\n",
    "    assert snapshot.memory_percent == 60.0\n",
    "    assert snapshot.disk_percent == 70.0\n",
    "    assert snapshot.network_sent == 1000\n",
    "    assert snapshot.network_recv == 2000\n",
    "    print(\"✅ MetricSnapshot creation test passed\")\n",
    "\n",
    "test_metric_snapshot_creation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708c2c0a",
   "metadata": {},
   "source": [
    "## Test PerformanceHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ac4d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_performance_history_init():\n",
    "    \"\"\"Test PerformanceHistory initialization\"\"\"\n",
    "    history = PerformanceHistory(max_samples=10)\n",
    "    \n",
    "    assert history.max_samples == 10\n",
    "    assert len(history.history) == 0\n",
    "    print(\"✅ PerformanceHistory init test passed\")\n",
    "\n",
    "test_performance_history_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd5958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_add_snapshot():\n",
    "    \"\"\"Test adding snapshots to history\"\"\"\n",
    "    history = PerformanceHistory(max_samples=5)\n",
    "    \n",
    "    # Add 3 snapshots\n",
    "    for i in range(3):\n",
    "        snapshot = MetricSnapshot(\n",
    "            timestamp=time.time(),\n",
    "            cpu_percent=50.0 + i,\n",
    "            memory_percent=60.0,\n",
    "            disk_percent=70.0\n",
    "        )\n",
    "        history.add_snapshot(snapshot)\n",
    "    \n",
    "    assert len(history.history) == 3\n",
    "    print(\"✅ Add snapshot test passed\")\n",
    "\n",
    "test_add_snapshot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70dae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_max_samples_limit():\n",
    "    \"\"\"Test that history respects max_samples limit\"\"\"\n",
    "    history = PerformanceHistory(max_samples=3)\n",
    "    \n",
    "    # Add 5 snapshots (exceeds max)\n",
    "    for i in range(5):\n",
    "        snapshot = MetricSnapshot(\n",
    "            timestamp=time.time(),\n",
    "            cpu_percent=50.0 + i,\n",
    "            memory_percent=60.0,\n",
    "            disk_percent=70.0\n",
    "        )\n",
    "        history.add_snapshot(snapshot)\n",
    "    \n",
    "    assert len(history.history) == 3\n",
    "    assert history.history[0].cpu_percent == 52.0  # First should be removed\n",
    "    print(\"✅ Max samples limit test passed\")\n",
    "\n",
    "test_max_samples_limit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_average():\n",
    "    \"\"\"Test calculating average metrics\"\"\"\n",
    "    history = PerformanceHistory(max_samples=10)\n",
    "    \n",
    "    # Add snapshots with known values\n",
    "    for i in range(3):\n",
    "        snapshot = MetricSnapshot(\n",
    "            timestamp=time.time(),\n",
    "            cpu_percent=30.0 + (i * 10),  # 30, 40, 50\n",
    "            memory_percent=60.0,\n",
    "            disk_percent=70.0\n",
    "        )\n",
    "        history.add_snapshot(snapshot)\n",
    "    \n",
    "    avg = history.get_average()\n",
    "    assert avg['cpu'] == 40.0  # (30+40+50)/3 = 40\n",
    "    assert avg['memory'] == 60.0\n",
    "    assert avg['disk'] == 70.0\n",
    "    print(\"✅ Get average test passed\")\n",
    "\n",
    "test_get_average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf23990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_peak():\n",
    "    \"\"\"Test finding peak metrics\"\"\"\n",
    "    history = PerformanceHistory(max_samples=10)\n",
    "    \n",
    "    # Add snapshots with varying values\n",
    "    for cpu in [30.0, 80.0, 50.0]:\n",
    "        snapshot = MetricSnapshot(\n",
    "            timestamp=time.time(),\n",
    "            cpu_percent=cpu,\n",
    "            memory_percent=60.0,\n",
    "            disk_percent=70.0\n",
    "        )\n",
    "        history.add_snapshot(snapshot)\n",
    "    \n",
    "    peak = history.get_peak()\n",
    "    assert peak['cpu'] == 80.0\n",
    "    assert peak['memory'] == 60.0\n",
    "    assert peak['disk'] == 70.0\n",
    "    print(\"✅ Get peak test passed\")\n",
    "\n",
    "test_get_peak()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb36b778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_trend():\n",
    "    \"\"\"Test trend detection\"\"\"\n",
    "    history = PerformanceHistory(max_samples=10)\n",
    "    \n",
    "    # Add increasing CPU values\n",
    "    for i in range(5):\n",
    "        snapshot = MetricSnapshot(\n",
    "            timestamp=time.time(),\n",
    "            cpu_percent=20.0 + (i * 10),  # 20, 30, 40, 50, 60\n",
    "            memory_percent=50.0,\n",
    "            disk_percent=70.0\n",
    "        )\n",
    "        history.add_snapshot(snapshot)\n",
    "    \n",
    "    trend = history.get_trend()\n",
    "    assert trend['cpu'] == 'increasing'\n",
    "    assert trend['memory'] == 'stable'\n",
    "    print(f\"✅ Get trend test passed: {trend}\")\n",
    "\n",
    "test_get_trend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbccf7dc",
   "metadata": {},
   "source": [
    "## Test ResourceMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606ccf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_resource_monitor_init():\n",
    "    \"\"\"Test ResourceMonitor initialization\"\"\"\n",
    "    monitor = ResourceMonitor(\n",
    "        cpu_threshold=80.0,\n",
    "        memory_threshold=85.0,\n",
    "        disk_threshold=90.0\n",
    "    )\n",
    "    \n",
    "    assert monitor.cpu_threshold == 80.0\n",
    "    assert monitor.memory_threshold == 85.0\n",
    "    assert monitor.disk_threshold == 90.0\n",
    "    assert hasattr(monitor, 'history')\n",
    "    print(\"✅ ResourceMonitor init test passed\")\n",
    "\n",
    "test_resource_monitor_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242ef1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_resource_monitor_update():\n",
    "    \"\"\"Test ResourceMonitor update method\"\"\"\n",
    "    monitor = ResourceMonitor()\n",
    "    \n",
    "    monitor.update(cpu=50.0, memory=60.0, disk=70.0)\n",
    "    \n",
    "    assert len(monitor.history.history) == 1\n",
    "    assert monitor.history.history[0].cpu_percent == 50.0\n",
    "    print(\"✅ ResourceMonitor update test passed\")\n",
    "\n",
    "test_resource_monitor_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3409a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_health_score_calculation():\n",
    "    \"\"\"Test health score calculation\"\"\"\n",
    "    monitor = ResourceMonitor()\n",
    "    \n",
    "    # Perfect system (0% usage)\n",
    "    monitor.update(cpu=0.0, memory=0.0, disk=0.0)\n",
    "    health = monitor.get_health_score()\n",
    "    assert health == 100\n",
    "    \n",
    "    # High usage system\n",
    "    monitor.update(cpu=90.0, memory=85.0, disk=80.0)\n",
    "    health = monitor.get_health_score()\n",
    "    assert health < 20  # Should be low\n",
    "    print(f\"✅ Health score test passed: {health}\")\n",
    "\n",
    "test_health_score_calculation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8585b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_alert_callback():\n",
    "    \"\"\"Test alert callback mechanism\"\"\"\n",
    "    monitor = ResourceMonitor(cpu_threshold=50.0)\n",
    "    alerts_received = []\n",
    "    \n",
    "    def alert_handler(metric, value, threshold):\n",
    "        alerts_received.append((metric, value, threshold))\n",
    "    \n",
    "    monitor.add_alert_callback(alert_handler)\n",
    "    \n",
    "    # Trigger CPU alert\n",
    "    monitor.update(cpu=80.0, memory=40.0, disk=30.0)\n",
    "    \n",
    "    assert len(alerts_received) == 1\n",
    "    assert alerts_received[0][0] == 'cpu'\n",
    "    assert alerts_received[0][1] == 80.0\n",
    "    print(f\"✅ Alert callback test passed: {alerts_received}\")\n",
    "\n",
    "test_alert_callback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e2b4d0",
   "metadata": {},
   "source": [
    "## Run All Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f62936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all tests\n",
    "pytest.main(['-v', '--tb=short', __file__])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
